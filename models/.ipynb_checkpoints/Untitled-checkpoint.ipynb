{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from models import BidirectionalLSTM\n",
    "\n",
    "import pickle\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vocab.pickle\", \"rb\") as vocabf:\n",
    "    vocab = pickle.load(vocabf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.5\n",
    "model = BidirectionalLSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, \n",
    "                          N_LAYERS, BIDIRECTIONAL, DROPOUT).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"Bidirectional.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[-0.0181,  0.0165, -0.0204,  ...,  0.0213,  0.0406, -0.0102],\n",
       "                      [ 0.0134,  0.0107, -0.0403,  ..., -0.0323,  0.0394,  0.0371],\n",
       "                      [-0.0885, -0.3074,  0.7475,  ..., -0.0910,  0.8222,  0.2536],\n",
       "                      ...,\n",
       "                      [ 0.0820, -0.0867, -0.1013,  ..., -0.0584,  0.0725,  0.0959],\n",
       "                      [-0.0711,  0.0348,  0.0509,  ...,  0.0532, -0.0346, -0.0408],\n",
       "                      [ 0.0094, -0.0319, -0.0387,  ..., -0.0087,  0.0027, -0.0095]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_ih_l0',\n",
       "              tensor([[ 0.0248, -0.0046, -0.0756,  ...,  0.0145, -0.1147, -0.0421],\n",
       "                      [ 0.0216,  0.0036, -0.0365,  ...,  0.0704, -0.0165, -0.0655],\n",
       "                      [ 0.0091, -0.0258, -0.0006,  ...,  0.1090, -0.0931, -0.0603],\n",
       "                      ...,\n",
       "                      [-0.1282, -0.0360, -0.0879,  ...,  0.0311, -0.0809, -0.0810],\n",
       "                      [-0.0490,  0.1068, -0.0722,  ...,  0.2139, -0.1126, -0.0854],\n",
       "                      [ 0.1641,  0.0943, -0.0225,  ...,  0.0921, -0.0654, -0.1187]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l0',\n",
       "              tensor([[-0.0019, -0.0777, -0.0386,  ..., -0.0772,  0.0172, -0.0170],\n",
       "                      [ 0.0545,  0.0006, -0.0163,  ..., -0.0220,  0.0723,  0.0519],\n",
       "                      [ 0.0696, -0.0468, -0.0152,  ...,  0.0559, -0.0525, -0.0170],\n",
       "                      ...,\n",
       "                      [-0.0869, -0.0588,  0.0801,  ...,  0.0211,  0.0114, -0.0230],\n",
       "                      [-0.0304,  0.0044,  0.0147,  ...,  0.0319,  0.0630,  0.0591],\n",
       "                      [-0.0004,  0.0330, -0.0727,  ...,  0.0172,  0.0879, -0.0020]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_ih_l0',\n",
       "              tensor([ 0.0025, -0.0915, -0.0225,  ..., -0.0785, -0.0101,  0.0553],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_hh_l0',\n",
       "              tensor([-0.0444, -0.0959,  0.0037,  ..., -0.0396, -0.0838,  0.0618],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_ih_l0_reverse',\n",
       "              tensor([[ 0.0399,  0.0801, -0.0507,  ..., -0.0831,  0.0608, -0.0236],\n",
       "                      [-0.0213, -0.0129,  0.0208,  ..., -0.0113, -0.0573,  0.0113],\n",
       "                      [ 0.0311,  0.0328,  0.0650,  ...,  0.0210, -0.0730, -0.0298],\n",
       "                      ...,\n",
       "                      [ 0.0135, -0.0528, -0.0430,  ...,  0.0426,  0.0035, -0.0045],\n",
       "                      [-0.0461, -0.0037,  0.0276,  ...,  0.0164,  0.0478, -0.0630],\n",
       "                      [ 0.0225, -0.0593, -0.0199,  ..., -0.0628,  0.0457,  0.0554]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l0_reverse',\n",
       "              tensor([[-0.0798,  0.0157,  0.0697,  ...,  0.0828, -0.0432, -0.0290],\n",
       "                      [-0.0028, -0.0714, -0.0060,  ...,  0.0652,  0.0681, -0.0493],\n",
       "                      [ 0.0196, -0.0137, -0.0084,  ..., -0.0182,  0.0444,  0.0008],\n",
       "                      ...,\n",
       "                      [ 0.0019,  0.0391,  0.0205,  ...,  0.0251, -0.0342, -0.0390],\n",
       "                      [-0.0563,  0.1086,  0.0172,  ...,  0.0920, -0.0731,  0.0405],\n",
       "                      [-0.0600, -0.0466, -0.0327,  ...,  0.0006, -0.0854, -0.0999]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_ih_l0_reverse',\n",
       "              tensor([-4.2098e-02, -5.7287e-02,  3.6371e-02,  ...,  6.8142e-03,\n",
       "                       8.4973e-05, -3.7877e-02], device='cuda:0')),\n",
       "             ('rnn.bias_hh_l0_reverse',\n",
       "              tensor([ 0.0713,  0.0062,  0.0237,  ..., -0.0398,  0.0601, -0.0615],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_ih_l1',\n",
       "              tensor([[ 0.0530,  0.0529, -0.0055,  ..., -0.0154, -0.0507,  0.0321],\n",
       "                      [-0.0726, -0.0166,  0.0749,  ...,  0.0267, -0.0091, -0.0084],\n",
       "                      [-0.0251, -0.0737,  0.0521,  ...,  0.0518,  0.0527,  0.0409],\n",
       "                      ...,\n",
       "                      [-0.0805, -0.0018,  0.0127,  ...,  0.0327, -0.0157, -0.0455],\n",
       "                      [-0.0771, -0.0682, -0.0213,  ...,  0.1261, -0.1168,  0.0807],\n",
       "                      [-0.0025,  0.0362,  0.0176,  ...,  0.0336,  0.0675,  0.0658]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l1',\n",
       "              tensor([[-0.0692,  0.0522, -0.0705,  ..., -0.0560,  0.0252,  0.0392],\n",
       "                      [ 0.0623,  0.0619, -0.0563,  ...,  0.0518,  0.0121,  0.0691],\n",
       "                      [ 0.0503, -0.0450, -0.0164,  ...,  0.0484,  0.0164,  0.0095],\n",
       "                      ...,\n",
       "                      [ 0.0385,  0.0224,  0.0275,  ...,  0.0760,  0.0303, -0.0222],\n",
       "                      [-0.0776,  0.0141, -0.0564,  ...,  0.0320,  0.0273, -0.0755],\n",
       "                      [ 0.0202,  0.0047, -0.0602,  ...,  0.0603,  0.0755,  0.0081]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_ih_l1',\n",
       "              tensor([-0.0510, -0.0122, -0.0239,  ..., -0.0541, -0.0225, -0.0874],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_hh_l1',\n",
       "              tensor([-0.0046,  0.0289, -0.1059,  ..., -0.0758, -0.0176, -0.0349],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_ih_l1_reverse',\n",
       "              tensor([[ 0.0250,  0.1104, -0.1238,  ..., -0.0492,  0.0861, -0.0679],\n",
       "                      [-0.0670,  0.0172, -0.0110,  ..., -0.0211,  0.0453,  0.0229],\n",
       "                      [ 0.0241, -0.0310, -0.0073,  ...,  0.0082,  0.0334, -0.0038],\n",
       "                      ...,\n",
       "                      [ 0.0262, -0.0798, -0.0307,  ...,  0.0594,  0.0707, -0.0210],\n",
       "                      [-0.0535, -0.0405,  0.1668,  ...,  0.1035,  0.0677,  0.0679],\n",
       "                      [ 0.0356, -0.0295,  0.0235,  ...,  0.0026,  0.0161,  0.0279]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l1_reverse',\n",
       "              tensor([[ 0.0348,  0.0645,  0.0014,  ..., -0.0062,  0.0329,  0.0562],\n",
       "                      [ 0.0010,  0.0493,  0.0105,  ...,  0.0293, -0.0497,  0.0108],\n",
       "                      [-0.0036,  0.0540, -0.0256,  ...,  0.0438, -0.0283,  0.0278],\n",
       "                      ...,\n",
       "                      [ 0.1017,  0.0185,  0.0869,  ...,  0.0212, -0.0218,  0.0332],\n",
       "                      [-0.0455,  0.0001, -0.0136,  ...,  0.0016,  0.0082,  0.0309],\n",
       "                      [ 0.0570, -0.0002, -0.0132,  ...,  0.0684,  0.0137,  0.0597]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_ih_l1_reverse',\n",
       "              tensor([ 0.0084, -0.1128,  0.0036,  ..., -0.0275, -0.1248, -0.0209],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_hh_l1_reverse',\n",
       "              tensor([ 0.0199, -0.0484, -0.0834,  ..., -0.0599, -0.0933, -0.0097],\n",
       "                     device='cuda:0')),\n",
       "             ('fc.weight',\n",
       "              tensor([[ 2.7122e-03,  7.8805e-04, -3.6077e-04,  4.7503e-04,  2.6325e-03,\n",
       "                        7.1061e-04,  1.0431e-03,  1.8107e-03, -7.9465e-04,  5.7144e-06,\n",
       "                       -1.7739e-04,  1.0773e-03,  1.4181e-03,  7.2472e-04,  4.4259e-03,\n",
       "                       -1.2184e-05, -3.2197e-03,  9.9601e-04,  1.1219e-03,  2.0399e-04,\n",
       "                       -1.4501e-04, -2.1061e-04, -1.1327e-02, -5.0158e-03,  6.9627e-03,\n",
       "                       -1.0850e-04,  1.0971e-03,  1.1366e-03, -1.7226e-03, -8.7463e-04,\n",
       "                        2.0205e-02,  3.3143e-03, -2.1236e-02,  8.1533e-04,  7.7044e-03,\n",
       "                        5.6020e-03,  1.8077e-03,  5.4633e-03, -3.4345e-03, -3.1810e-03,\n",
       "                       -8.9520e-04,  2.9075e-04,  2.8020e-04,  8.9267e-04,  1.0410e-03,\n",
       "                       -3.7422e-03,  9.3192e-05,  1.0110e-03, -2.0144e-03, -3.5194e-02,\n",
       "                       -7.7325e-04,  3.6550e-03, -1.3121e-03,  9.0185e-04, -2.5851e-02,\n",
       "                       -6.2036e-04, -1.0398e-03, -5.4925e-04,  1.3057e-05, -4.6257e-04,\n",
       "                       -1.0710e-03, -6.7452e-03, -2.3751e-03,  1.1282e-04, -1.3021e-03,\n",
       "                       -7.8282e-03, -1.3286e-02, -8.1947e-03,  7.6847e-04, -9.7155e-06,\n",
       "                       -7.2540e-04, -2.0878e-04, -3.3589e-04, -2.0954e-03, -1.5169e-02,\n",
       "                        1.5644e-03,  3.2474e-04, -1.3755e-03, -2.1376e-02, -2.2530e-02,\n",
       "                       -5.3073e-04,  1.0297e-03,  1.4060e-03,  3.7558e-02,  2.1481e-03,\n",
       "                        1.0483e-02,  4.5998e-03, -2.3234e-03,  7.7128e-03,  6.0997e-03,\n",
       "                       -2.1580e-03,  6.0831e-03, -2.9561e-03, -1.9260e-03,  1.7302e-02,\n",
       "                        2.9923e-03,  5.3926e-04, -9.9634e-03,  5.4394e-03,  2.6377e-03,\n",
       "                       -2.2489e-04,  2.1102e-04,  8.8683e-03,  1.0887e-03, -3.1517e-03,\n",
       "                       -1.2423e-03, -1.6085e-02, -8.4691e-03, -2.5119e-03,  2.3522e-02,\n",
       "                        8.8787e-04, -8.4701e-04,  2.5392e-03,  1.6772e-02, -3.1374e-02,\n",
       "                        4.4769e-04, -8.8232e-04, -1.9960e-03, -5.2233e-03,  2.2822e-03,\n",
       "                       -2.4917e-03,  1.2198e-03,  3.6646e-03, -4.4349e-03,  1.3760e-03,\n",
       "                       -3.3050e-03,  2.0244e-02, -2.1805e-03,  1.4733e-03,  7.3467e-03,\n",
       "                        4.6957e-04,  2.6367e-04, -6.5641e-04, -8.9281e-03, -1.2885e-03,\n",
       "                       -2.3298e-03,  1.3030e-03, -8.7003e-03, -1.7120e-03,  6.8457e-04,\n",
       "                        1.8899e-02, -5.8538e-04,  1.0252e-03, -1.2251e-02,  8.0199e-04,\n",
       "                        6.0241e-05, -8.7061e-04, -2.0482e-02,  4.1161e-04,  4.0552e-03,\n",
       "                       -4.3280e-04, -5.5545e-03,  7.6110e-04, -2.0649e-03,  1.1946e-03,\n",
       "                        9.9359e-05, -2.2480e-03, -3.3105e-03, -1.7132e-03,  5.7448e-04,\n",
       "                        2.0435e-03,  2.7563e-03, -1.2465e-02,  4.5351e-03, -3.8785e-04,\n",
       "                        3.7187e-04, -1.9206e-04,  7.2319e-04,  1.4436e-02, -2.8667e-03,\n",
       "                        1.5884e-03,  4.7084e-03,  6.2470e-03, -2.9373e-05,  1.0776e-03,\n",
       "                        3.1969e-03,  2.5283e-04, -1.5248e-03, -1.5696e-03, -1.8972e-02,\n",
       "                       -2.5160e-02, -6.2556e-04, -8.0896e-04,  5.4484e-04,  4.5822e-03,\n",
       "                        2.8475e-03, -7.5547e-05,  1.1163e-03, -1.5763e-03,  1.0508e-03,\n",
       "                        5.5086e-04,  3.5089e-05, -3.5140e-03,  5.6897e-03,  9.3291e-03,\n",
       "                        1.5589e-03, -5.4198e-04,  1.6800e-04, -4.7531e-03,  1.1608e-03,\n",
       "                       -3.2733e-04,  4.0113e-04, -5.5370e-04,  2.1391e-04,  1.1100e-03,\n",
       "                       -8.6259e-04,  1.2097e-02,  6.0034e-03, -1.2801e-03, -1.1067e-02,\n",
       "                       -3.1636e-04, -1.4157e-03,  1.1961e-03, -5.6409e-03, -1.3771e-03,\n",
       "                       -1.2634e-02,  1.2122e-03, -2.4014e-03, -1.5956e-03, -1.4495e-03,\n",
       "                       -4.6047e-04, -1.9801e-03, -2.6880e-03, -1.2833e-03, -1.2258e-03,\n",
       "                       -1.2538e-02, -5.0438e-04,  9.5451e-04,  6.8220e-03,  7.3704e-04,\n",
       "                        4.1393e-03,  7.6701e-04,  7.9372e-04, -1.2024e-02, -2.6662e-04,\n",
       "                       -1.0070e-03,  8.3354e-04,  1.4215e-02, -2.6857e-04,  7.4534e-04,\n",
       "                       -1.3408e-03,  5.2993e-04,  1.6722e-02, -1.4423e-03,  1.0350e-04,\n",
       "                       -1.4079e-04, -7.8613e-03,  1.6553e-02, -5.9529e-04, -5.4963e-04,\n",
       "                        1.8396e-04,  5.8943e-03,  5.7817e-03,  1.3036e-04,  1.0402e-02,\n",
       "                       -2.6303e-04,  6.2600e-02, -6.7356e-03,  3.9762e-02,  1.4778e-01,\n",
       "                        2.8334e-02, -6.1607e-02,  4.0839e-03, -1.6528e-02,  5.2387e-02,\n",
       "                       -5.7928e-02,  1.9979e-02, -2.5857e-02,  6.2330e-03, -8.8604e-02,\n",
       "                       -2.7425e-02,  4.3445e-02,  4.9125e-02,  6.7311e-02,  2.9871e-02,\n",
       "                       -2.9593e-02, -6.4241e-03, -1.7445e-02,  2.6069e-03,  2.2615e-02,\n",
       "                        1.4433e-02,  2.5116e-03, -1.3181e-03,  5.4658e-02,  1.2542e-03,\n",
       "                       -4.2008e-02, -9.3238e-03,  8.2913e-03, -1.8504e-02, -3.4469e-02,\n",
       "                       -5.0835e-02,  4.4612e-02,  1.2438e-03, -5.7248e-02, -5.4682e-03,\n",
       "                        2.8875e-03,  3.4869e-03, -4.9665e-02, -3.6450e-03,  2.4619e-02,\n",
       "                       -5.2586e-02,  4.9183e-02, -5.8491e-02,  3.3372e-04,  8.4686e-03,\n",
       "                       -5.1606e-02, -1.5622e-02, -3.2854e-02, -7.7298e-02,  2.1629e-02,\n",
       "                       -3.0036e-02, -1.5759e-02,  6.4121e-02,  5.1484e-02,  1.7154e-02,\n",
       "                        1.0889e-02, -7.5400e-02, -4.4230e-02,  1.2711e-01,  2.0832e-02,\n",
       "                        2.1827e-02,  4.9732e-02,  6.0321e-02,  4.7264e-02,  9.3084e-03,\n",
       "                       -1.1512e-02,  9.9010e-03, -1.0637e-01, -5.2514e-03, -4.0921e-02,\n",
       "                        5.0869e-02, -3.0916e-02, -6.2706e-02, -5.4213e-02, -5.1895e-03,\n",
       "                        2.9969e-03,  3.6452e-03,  2.8290e-02,  1.4894e-02,  1.6190e-02,\n",
       "                       -3.7364e-02, -3.1020e-02, -3.3320e-02,  5.8249e-02,  2.4931e-03,\n",
       "                       -1.1859e-01,  2.8935e-02, -1.1163e-02,  4.9671e-04, -1.3840e-02,\n",
       "                       -1.1888e-02,  2.1512e-02, -3.3613e-02, -3.2947e-03, -5.7012e-03,\n",
       "                       -1.2240e-02, -6.9976e-03, -1.3579e-02, -3.8471e-02,  1.4336e-02,\n",
       "                       -6.3112e-02,  2.2274e-03,  1.0320e-01,  2.2389e-02,  9.0104e-03,\n",
       "                        3.6853e-02, -1.8815e-02, -1.7069e-01, -6.3768e-03, -6.9702e-04,\n",
       "                        8.4598e-02,  1.0994e-02,  9.9221e-02, -7.2418e-02, -5.6433e-02,\n",
       "                       -3.7543e-03, -3.8645e-02, -3.2658e-02,  1.0660e-02,  2.3265e-02,\n",
       "                        8.2425e-02, -2.4874e-02,  7.7063e-03, -2.1803e-02, -1.5354e-02,\n",
       "                       -3.0553e-02,  9.8279e-02,  4.7059e-02, -2.2971e-03, -5.2382e-02,\n",
       "                        2.4446e-02, -1.8535e-02, -8.2802e-03, -3.1119e-02, -5.5256e-02,\n",
       "                       -1.9074e-02, -4.2856e-02, -6.1289e-03,  2.2638e-02, -3.8888e-02,\n",
       "                        2.0058e-02, -5.3104e-03, -6.2161e-03,  7.4432e-02,  1.0085e-01,\n",
       "                       -2.3369e-02,  9.0800e-03,  8.7145e-02, -5.1250e-02,  8.2302e-03,\n",
       "                        1.3329e-01,  6.9996e-03,  7.7544e-02, -4.5613e-02, -3.1235e-02,\n",
       "                        5.8359e-02,  5.5363e-03,  6.2618e-02,  3.6919e-02, -2.1978e-02,\n",
       "                       -1.7697e-02, -4.5079e-02,  5.5984e-02,  4.2295e-03,  6.3718e-03,\n",
       "                       -5.1317e-02,  8.0935e-02, -7.2547e-02,  2.3412e-02,  1.8683e-02,\n",
       "                        5.6325e-02, -2.6381e-02,  2.0997e-02,  3.5716e-02,  2.4875e-02,\n",
       "                       -5.5366e-02, -4.5190e-02,  9.0980e-02, -7.4716e-02,  1.0022e-01,\n",
       "                        5.5652e-02, -1.1342e-02, -6.8412e-04, -2.8458e-02,  1.4862e-02,\n",
       "                       -9.4658e-03,  3.7354e-02, -6.6812e-02,  2.2036e-02,  2.4787e-02,\n",
       "                       -1.2049e-02,  2.9125e-02, -1.0163e-02, -7.8926e-02,  7.9099e-02,\n",
       "                       -7.5514e-04,  4.4831e-02, -5.4356e-02,  6.6949e-02, -4.6804e-02,\n",
       "                        5.1477e-02, -5.4522e-02, -6.8625e-02,  2.1214e-02,  2.5627e-03,\n",
       "                       -1.2400e-01,  1.6799e-02, -9.5554e-02,  5.1083e-02, -6.8875e-02,\n",
       "                       -1.1289e-02, -1.9991e-02,  1.0838e-04,  1.0228e-02, -1.1505e-01,\n",
       "                       -5.1127e-02,  4.1372e-02, -2.6696e-03, -2.3318e-03,  8.5004e-02,\n",
       "                        3.3743e-03, -3.2870e-02, -5.7078e-02,  1.4610e-02,  8.5867e-02,\n",
       "                        2.6347e-02,  5.1187e-02, -7.2671e-02, -1.4014e-02, -9.6962e-03,\n",
       "                        1.2274e-01,  5.3299e-02, -1.0052e-01, -2.7714e-02,  7.7465e-02,\n",
       "                        6.2272e-02,  5.2943e-02, -5.1663e-03,  2.0517e-02,  8.3040e-03,\n",
       "                        2.6000e-02, -8.4494e-02,  5.6773e-04,  6.3528e-02, -7.5580e-02,\n",
       "                        6.4375e-02,  7.1216e-02,  1.4419e-02,  8.5417e-03, -3.8135e-03,\n",
       "                        2.2529e-02,  1.4740e-02]], device='cuda:0')),\n",
       "             ('fc.bias', tensor([0.0054], device='cuda:0'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = model.state_dict()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_tensor(sentence, vocab):\n",
    "    nlp = spacy.load(\"en\")\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [vocab[t] for t in tokenized]\n",
    "\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = sentence_to_tensor(\"This film is great\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "gate_ids = set(zip(range(4), [\"i\", \"f\", \"g\", \"o\"]))\n",
    "w_tensor_ids = [\"i\", \"h\"]\n",
    "\n",
    "for l in range(N_LAYERS):\n",
    "    for w_tensor_id in w_tensor_ids:\n",
    "        w_tensor = f\"rnn.weight_{w_tensor_id}h_l{l}\"\n",
    "        for idx, id in gate_ids:\n",
    "            weights[f\"W{w_tensor_id}{id}\"] = d[w_tensor][(idx*HIDDEN_DIM):((idx+1)*HIDDEN_DIM)]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25002, 100])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " d[\"embedding.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded = np.array([])\n",
    "for i in input:\n",
    "    np.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 6.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(embedded, [1, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
